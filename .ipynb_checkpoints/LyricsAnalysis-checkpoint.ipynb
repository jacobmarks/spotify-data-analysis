{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51026ffb-c7fa-4aa7-b368-1f01990cfaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from my_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78eebd0d-268d-4d5a-8383-04d95f677753",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['d', '*', 's', '+', '^', 'x', 'o']\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'brown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6f3714-653e-490f-85a4-d016832fac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_file = \"data/processed/streaming.csv\"\n",
    "artists_file = \"data/processed/artists.csv\"\n",
    "tracks_file = \"data/processed/tracks_with_lyrics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e7f4ab-e79e-459c-8ce2-eedfbdf11a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df = pd.read_csv(streaming_file, index_col = None)\n",
    "artists_df = pd.read_csv(artists_file, index_col = None)\n",
    "tracks_df = pd.read_csv(tracks_file, index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d13516-9e08-4393-be5a-450cf1b48b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df = convert_to_datetime(streaming_df, 'dateTime')\n",
    "tracks_df = convert_to_datetime(tracks_df, 'timeAdded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ea890e-252a-44af-bdc9-a50ff58ce983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sailing the Sunset ****, I\\'m a bit of a king Granny would take a trip, I\\'ve been bending the strings Got hammers in both my hands, such a delicate touch They say I\\'m from Amsterdam, does that make me Dutch?   Please don\\'t remember me, for what I did last night, oh Please don\\'t remember me Lord and children Please don\\'t remember me, it\\'s only 1980 It\\'s only 1983  Smoking the ****, feeling my own light My brother\\'s a keeper, I married a TV wife The devil\\'s Camaro, parked in thе high school lot A little sombrero \\'cause tеacher was way too hot   Please don\\'t remember me, for what I did last night, oh Please don\\'t remember me Listen Lord now Please don\\'t remember me, it\\'s only 1980 It\\'s only 1983   Tell my love \"But leave me never\" Can\\'t complain about the weather Snowing at the rainbow, have a ball Cut my teeth down at the whiskey GTO\\'s tried to kiss me One more song, they have seen it all     Please don\\'t remember me, for what I did last night, oh Please don\\'t remember me What\\'d I say Lord? Please don\\'t remember me, it\\'s only 1980 It\\'s only 1983 Please don\\'t remember me, for what I did with David You know I\\'m talkin\\' David Lee Am I ready? Please don\\'t remember me, for what I did last night, oh I guess I played a Flying V You might also like'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_df.loc[1]['lyrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1914a0-152e-41f5-8156-3d90448bd62d",
   "metadata": {},
   "source": [
    "* [Perplexity procedure](https://www.mathworks.com/help/textanalytics/ug/choose-number-of-topics-for-LDA-model.html)\n",
    "* [Perplexity definition](http://qpleple.com/perplexity-to-evaluate-topic-models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca804228-ae24-40ec-be9d-da787dcc02ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import wordpunct_tokenize as tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c3d2aef-6bcd-499a-8f64-e9995c328633",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_words = words.words()\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['song', 'intro', 'chorus', 'bridge', 'outro', 'ft', 'get', 'take',\n",
    "                  'oh', 'ooh', 'ee', 'lil', 'like', 'let', 'got', 'one', 'know', 'yeah',\n",
    "                  'go', 'might', 'could', 'never', 'mr', 'ms', 'dan', 'much', 'come', 'back',\n",
    "                  'wanna', 'would', 'yuh', 'la', 'le', 'make', 'remix', 'de', 'feat', 'na', \n",
    "                  'bring', 'ah', 'right', 'nothing', 'try', 'mm', 'aa', 'aah', 'nah', 'im',\n",
    "                  'huh', 'tell', 'spotify', 'dont', 'ill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aa3f47d-5e2b-4dd3-b659-da792cafa192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_lyrics_for_lda(tracks_df, allowed_words, stop_words):\n",
    "    '''format the lyrics from a dataframe for Latent Dirichlet Analysis. \n",
    "        This involves getting rid of profanity (represented by strings of ***),\n",
    "        punctuation, stop words, and all words not in the allowed words list'''\n",
    "    lyrics = tracks_df['lyrics'].dropna().map(lambda x: re.sub('[_,\\\\.!?\\\\d*\\']', '', x).lower())\n",
    "    lyrics = lyrics.values.tolist()\n",
    "    new_lyrics = []\n",
    "    for song in tqdm(lyrics):\n",
    "        tokens = tokenize(song)\n",
    "        allowed_tokens = [t for t in tokens if t in allowed_words and t not in stop_words]\n",
    "        new_lyrics.append(' '.join(allowed_tokens))\n",
    "    return new_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "373d52e6-f632-45b2-ae82-b40f559a8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_lyrics = format_lyrics_for_lda(tracks_df, allowed_words, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4f9b186-fc36-4f3f-88a7-59184199f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "lda_lyrics_file = \"data/processed/lda_input_lyrics.p\"\n",
    "# pickle.dump({'lyrics':lda_lyrics}, open(lda_lyrics_file, \"wb\"))\n",
    "\n",
    "with open(lda_lyrics_file,'rb') as read_file:\n",
    "    lda_lyrics = pickle.load(read_file)['lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30531eb8-647d-484f-aa3f-a19c534204ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words=stop_words, lowercase=True, min_df = 40, max_df = 0.6)\n",
    "x_counts = count_vect.fit_transform(lda_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a509408d-02e1-457e-9ae7-a3d5b6d58867",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "x_tfidf = tfidf_transformer.fit_transform(x_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46954ad7-f483-496e-af3b-84a4468161f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 25\n",
    "lda = LDA(n_components = dimension)\n",
    "lda_array = lda.fit_transform(x_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59b8643d-2a88-4428-bf38-3f04c223022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = [lda.components_[i] for i in range(len(lda.components_))]\n",
    "features = count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82318e8f-fdd0-43cd-b0b4-75b930c67ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_essential_words(features, components, nwords = 5):\n",
    "    important_words = []\n",
    "    for j in range(len(components)):\n",
    "        iw = sorted(features, key = lambda x: components[j][features.index(x)], reverse = True)[:nwords]\n",
    "        print(iw)\n",
    "        important_words.append(iw)\n",
    "    return important_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "055886f2-8858-44d2-a5c3-5ca0e5f8710a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['notice', 'river', 'expensive', 'supposed', 'drip']\n",
      "['woman', 'happen', 'anything', 'met', 'night']\n",
      "['way', 'care', 'somewhere', 'breathing', 'ne']\n",
      "['da', 'young', 'black', 'jay', 'west']\n",
      "['daylight', 'youve', 'ha', 'se', 'free']\n",
      "['high', 'rat', 'die', 'live', 'amen']\n",
      "['bye', 'beware', 'worried', 'runaway', 'awake']\n",
      "['groove', 'came', 'doubt', 'spoke', 'bigger']\n",
      "['ay', 'bloom', 'wonderful', 'following', 'series']\n",
      "['di', 'stoner', 'son', 'velvet', 'sea']\n",
      "['really', 'answer', 'bad', 'bit', 'sending']\n",
      "['breathe', 'loose', 'waiting', 'pure', 'thank']\n",
      "['th', 'sunshine', 'alright', 'bae', 'baby']\n",
      "['closer', 'easily', 'laura', 'keep', 'wrap']\n",
      "['guitar', 'horizon', 'pause', 'carried', 'lick']\n",
      "['love', 'baby', 'time', 'want', 'see']\n",
      "['low', 'dancing', 'glow', 'bout', 'prepared']\n",
      "['tear', 'push', 'stretch', 'alive', 'paradise']\n",
      "['ancient', 'sleep', 'funky', 'guitar', 'staring']\n",
      "['un', 'tu', 'mi', 'en', 'te']\n",
      "['waiting', 'shut', 'swallow', 'loving', 'lying']\n",
      "['pa', 'four', 'three', 'frank', 'two']\n",
      "['aw', 'tea', 'sunlight', 'ha', 'alright']\n",
      "['wed', 'sleeping', 'patient', 'honestly', 'within']\n",
      "['color', 'keeping', 'frozen', 'moonlight', 'plain']\n"
     ]
    }
   ],
   "source": [
    "important_words = get_essential_words(features, components, nwords = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c72ae5-78d6-41e1-bfea-dd65df41d0b5",
   "metadata": {},
   "source": [
    "#### BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0baa787-fe8b-4934-9836-6820f2dc335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = tracks_df['lyrics'].dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "559ae489-31a8-43de-a204-8798441d8376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70b1bd31-9d3b-43c1-a7e2-0c381ba3a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTopic(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9e911-4d30-4670-8550-21f4ebe99046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0f6b8be7404afca034bb9ff6406ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 18:14:48,843 - BERTopic - Transformed documents to Embeddings\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "topics, probabilities = model.fit_transform(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bb5197-44ee-4354-820d-b61977ce7d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_topic_freq().head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548caad2-d9d9-4567-a7ab-9f2176c7308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a9e78f-6895-4e8d-a69f-39ee982720e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = sorted(list(set((' '.join(artists_df.dropna()['genres'].tolist())).split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d892462-fe10-40f0-95ab-5cf7d1c0d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_artist_genres_df(artists_df, genres):\n",
    "    artists_with_genres_df = artists_df.dropna()\n",
    "    genres_df = artists_with_genres_df[['name']]\n",
    "    genres_df = genres_df.rename(columns={\"name\": \"artistName\"})\n",
    "    for genre in genres:\n",
    "        genres_df[genre] = False\n",
    "        inds = artists_with_genres_df[artists_with_genres_df['genres'].str.contains(genre)].index.tolist()\n",
    "        for i in inds:\n",
    "            genres_df.at[i, genre] = True\n",
    "    return genres_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf78ee-ce75-42a2-94fe-e1ae88815756",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['rock', 'rap', 'hip hop', 'jazz', 'house', 'folk', 'alternative', 'pop', 'r&b', 'soul']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d4e36-4c1e-4841-96f0-dd92ccce0942",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_genres_df = gen_artist_genres_df(artists_df, genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e103528-f34d-4709-87a5-f833a2d625ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_initial_track_genres_df(tracks_df, artist_genres_df):\n",
    "    tracks_with_lyrics_df = tracks_df.dropna()\n",
    "    artist_genre_columns = list(artist_genres_df.columns)\n",
    "    track_columns = ['uri', 'trackName', 'lyrics']\n",
    "    columns = track_columns + artist_genre_columns\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    for i in range(len(artist_genres_df)):\n",
    "        artistName = artist_genres_df.iloc[i]['artistName']\n",
    "        artist_genres = artist_genres_df.iloc[i]\n",
    "        genres_dict = {k: artist_genres[k] for k in artist_genre_columns}\n",
    "        # print(genres_dict)\n",
    "        artist_tracks = tracks_with_lyrics_df[tracks_with_lyrics_df['artistName'] == artistName]\n",
    "        for j in range(len(artist_tracks)):\n",
    "            # print(j)\n",
    "            track = artist_tracks.iloc[j]\n",
    "            track_dict = {k: track[k] for k in track_columns}\n",
    "            row_dict = {**track_dict, **genres_dict}\n",
    "            # row_dict = track_dict.update(genres_dict)\n",
    "            # print(row_dict)\n",
    "            new_row = pd.Series(row_dict)\n",
    "            df = pd.concat([df, new_row.to_frame().T], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ddf409-b876-46f3-b392-2425151ca151",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_track_genres_df = gen_initial_track_genres_df(tracks_df, artist_genres_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa81c2d-85d8-4c0d-9f2c-bb51f3c055cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_track_genres_df[genres].astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550110a-1119-41e0-8682-acce5adc6385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
